{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1357f816",
   "metadata": {
    "papermill": {
     "duration": 0.003874,
     "end_time": "2025-11-30T13:27:15.778624",
     "exception": false,
     "start_time": "2025-11-30T13:27:15.774750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Robotics Experiment Intelligence Agent\n",
    "\n",
    "This notebook implements an Enterprise-style Experiment Intelligence Agent for robotics research. \n",
    "The agent ingests synthetic TurtleBot3 experiment logs, computes localization metrics, compares navigation configurations, \n",
    "and answers research questions without manual spreadsheet analysis.\n",
    "\n",
    "Instead of manually parsing ROS data, aligning trajectories, and calculating RMSE or CPU usage across runs, \n",
    "the system uses a multi-agent architecture:\n",
    "\n",
    "- **DataAnalysisAgent** — deterministic metrics computation from CSV logs  \n",
    "- **ExplanationAgent** — converts numeric results into human-readable insights  \n",
    "- **MemoryStore** — preserves context across queries for iterative analysis\n",
    "\n",
    "All quantitative evaluation (RMSE, MAE, peak error, CPU/memory) is computed transparently using Python and remains reproducible.  \n",
    "The agent layer adds reasoning and interactivity, similar to a research assistant, allowing the user to ask questions such as:\n",
    "\n",
    "> “Which configuration achieved the lowest localization error across all runs?”\n",
    "\n",
    "or\n",
    "\n",
    "> “How does Gmapping affect performance for 10-minute missions?”\n",
    "\n",
    "This notebook demonstrates the prototype using synthetic TurtleBot3 runs at 5 Hz across four configurations and three durations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd49d36e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:15.786212Z",
     "iopub.status.busy": "2025-11-30T13:27:15.785855Z",
     "iopub.status.idle": "2025-11-30T13:27:17.927263Z",
     "shell.execute_reply": "2025-11-30T13:27:17.925753Z"
    },
    "papermill": {
     "duration": 2.147598,
     "end_time": "2025-11-30T13:27:17.929375",
     "exception": false,
     "start_time": "2025-11-30T13:27:15.781777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents-intensive-capstone-project  synthetic-tb3-experiments-for-agent-analysis\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "!ls /kaggle/input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5dff19a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:17.938267Z",
     "iopub.status.busy": "2025-11-30T13:27:17.937136Z",
     "iopub.status.idle": "2025-11-30T13:27:18.069350Z",
     "shell.execute_reply": "2025-11-30T13:27:18.067693Z"
    },
    "papermill": {
     "duration": 0.138754,
     "end_time": "2025-11-30T13:27:18.071368",
     "exception": false,
     "start_time": "2025-11-30T13:27:17.932614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithma_gmappingoff_10min.csv  algorithmb_gmappingoff_10min.csv\r\n",
      "algorithma_gmappingoff_2min.csv   algorithmb_gmappingoff_2min.csv\r\n",
      "algorithma_gmappingoff_5min.csv   algorithmb_gmappingoff_5min.csv\r\n",
      "algorithma_gmappingon_10min.csv   algorithmb_gmappingon_10min.csv\r\n",
      "algorithma_gmappingon_2min.csv\t  algorithmb_gmappingon_2min.csv\r\n",
      "algorithma_gmappingon_5min.csv\t  algorithmb_gmappingon_5min.csv\r\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/kaggle/input/synthetic-tb3-experiments-for-agent-analysis\")\n",
    "\n",
    "!ls \"$DATA_DIR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60ff473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.080087Z",
     "iopub.status.busy": "2025-11-30T13:27:18.079692Z",
     "iopub.status.idle": "2025-11-30T13:27:18.095740Z",
     "shell.execute_reply": "2025-11-30T13:27:18.094478Z"
    },
    "papermill": {
     "duration": 0.022808,
     "end_time": "2025-11-30T13:27:18.097546",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.074738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def load_run(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a single experiment CSV and validate columns.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    required_cols = [\"timestamp\", \"x\", \"y\", \"x_gt\", \"y_gt\", \"v_linear\", \"v_angular\", \"cpu\", \"memory\"]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {file_path}: {missing}\")\n",
    "    return df\n",
    "\n",
    "def parse_config_from_name(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse config info from filename pattern:\n",
    "    algorithma_gmappingon_5min.csv\n",
    "    \"\"\"\n",
    "    base = Path(filename).stem.lower()  \n",
    "    parts = base.split(\"_\")\n",
    "\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Unexpected filename pattern: {filename}\")\n",
    "\n",
    "    algo_raw = parts[0]   # 'algorithma'\n",
    "    gmap_raw = parts[1]   # 'gmappingon'\n",
    "    dur_raw  = parts[2]   # '5min'\n",
    "\n",
    "    algo_letter = algo_raw.replace(\"algorithm\", \"\").upper()  # 'A' or 'B'\n",
    "    gmapping    = \"ON\" if \"on\" in gmap_raw else \"OFF\"\n",
    "    duration    = int(dur_raw.replace(\"min\", \"\").strip())\n",
    "\n",
    "    return {\n",
    "        \"algorithm\": f\"Algorithm{algo_letter}\",\n",
    "        \"gmapping\": gmapping,\n",
    "        \"duration_min\": duration,\n",
    "    }\n",
    "\n",
    "def compute_localization_metrics(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Compute localization + resource metrics for one run.\"\"\"\n",
    "    dx = df[\"x\"] - df[\"x_gt\"]\n",
    "    dy = df[\"y\"] - df[\"y_gt\"]\n",
    "    err = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    mae  = float(np.mean(np.abs(err)))\n",
    "    max_err = float(np.max(err))\n",
    "\n",
    "    cpu_mean = float(df[\"cpu\"].mean())\n",
    "    mem_mean = float(df[\"memory\"].mean())\n",
    "\n",
    "    return {\n",
    "        \"rmse_error\": rmse,\n",
    "        \"mae_error\": mae,\n",
    "        \"max_error\": max_err,\n",
    "        \"cpu_mean\": cpu_mean,\n",
    "        \"memory_mean\": mem_mean,\n",
    "    }\n",
    "\n",
    "def summarize_all_runs(data_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Scan CSVs in data_dir and build a summary table with config + metrics.\"\"\"\n",
    "    rows = []\n",
    "    for csv_path in data_dir.glob(\"*.csv\"):\n",
    "        name_lower = csv_path.name.lower()\n",
    "        # Only process files that look like our experiment logs\n",
    "        if not name_lower.startswith(\"algorithma_\") and not name_lower.startswith(\"algorithmb_\"):\n",
    "            continue\n",
    "\n",
    "        df = load_run(csv_path)\n",
    "        cfg = parse_config_from_name(csv_path.name)\n",
    "        metrics = compute_localization_metrics(df)\n",
    "\n",
    "        row = {\n",
    "            \"file\": csv_path.name,\n",
    "            **cfg,\n",
    "            **metrics,\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    if summary_df.empty:\n",
    "        raise RuntimeError(f\"No valid experiment CSVs found in {data_dir}\")\n",
    "\n",
    "    return summary_df.sort_values([\"algorithm\", \"gmapping\", \"duration_min\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3facc630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.106277Z",
     "iopub.status.busy": "2025-11-30T13:27:18.105177Z",
     "iopub.status.idle": "2025-11-30T13:27:18.376892Z",
     "shell.execute_reply": "2025-11-30T13:27:18.375465Z"
    },
    "papermill": {
     "duration": 0.277923,
     "end_time": "2025-11-30T13:27:18.378746",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.100823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>gmapping</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>rmse_error</th>\n",
       "      <th>mae_error</th>\n",
       "      <th>max_error</th>\n",
       "      <th>cpu_mean</th>\n",
       "      <th>memory_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>algorithma_gmappingoff_2min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093685</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.207659</td>\n",
       "      <td>28.058656</td>\n",
       "      <td>390.366364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algorithma_gmappingoff_5min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218408</td>\n",
       "      <td>0.191426</td>\n",
       "      <td>0.429640</td>\n",
       "      <td>28.523656</td>\n",
       "      <td>384.248801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algorithma_gmappingoff_10min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.428548</td>\n",
       "      <td>0.373248</td>\n",
       "      <td>0.773025</td>\n",
       "      <td>28.143886</td>\n",
       "      <td>380.305109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>algorithma_gmappingon_2min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>ON</td>\n",
       "      <td>2</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>0.045292</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>35.009435</td>\n",
       "      <td>430.102479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>algorithma_gmappingon_5min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>ON</td>\n",
       "      <td>5</td>\n",
       "      <td>0.111942</td>\n",
       "      <td>0.098839</td>\n",
       "      <td>0.210905</td>\n",
       "      <td>35.565945</td>\n",
       "      <td>424.342170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>algorithma_gmappingon_10min.csv</td>\n",
       "      <td>AlgorithmA</td>\n",
       "      <td>ON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.217239</td>\n",
       "      <td>0.190038</td>\n",
       "      <td>0.389361</td>\n",
       "      <td>35.123617</td>\n",
       "      <td>420.364987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algorithmb_gmappingoff_2min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148677</td>\n",
       "      <td>0.133288</td>\n",
       "      <td>0.313018</td>\n",
       "      <td>32.005446</td>\n",
       "      <td>402.789335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>algorithmb_gmappingoff_5min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>OFF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.332668</td>\n",
       "      <td>0.292338</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>32.744006</td>\n",
       "      <td>395.336306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>algorithmb_gmappingoff_10min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>OFF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.648087</td>\n",
       "      <td>0.565424</td>\n",
       "      <td>1.175991</td>\n",
       "      <td>32.121463</td>\n",
       "      <td>390.364294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algorithmb_gmappingon_2min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>ON</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083354</td>\n",
       "      <td>0.075870</td>\n",
       "      <td>0.158725</td>\n",
       "      <td>40.070506</td>\n",
       "      <td>463.065771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>algorithmb_gmappingon_5min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>ON</td>\n",
       "      <td>5</td>\n",
       "      <td>0.183181</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.333666</td>\n",
       "      <td>40.746644</td>\n",
       "      <td>455.533681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>algorithmb_gmappingon_10min.csv</td>\n",
       "      <td>AlgorithmB</td>\n",
       "      <td>ON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.351066</td>\n",
       "      <td>0.307841</td>\n",
       "      <td>0.635364</td>\n",
       "      <td>40.131652</td>\n",
       "      <td>450.300213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file   algorithm gmapping  duration_min  \\\n",
       "7    algorithma_gmappingoff_2min.csv  AlgorithmA      OFF             2   \n",
       "1    algorithma_gmappingoff_5min.csv  AlgorithmA      OFF             5   \n",
       "0   algorithma_gmappingoff_10min.csv  AlgorithmA      OFF            10   \n",
       "6     algorithma_gmappingon_2min.csv  AlgorithmA       ON             2   \n",
       "5     algorithma_gmappingon_5min.csv  AlgorithmA       ON             5   \n",
       "8    algorithma_gmappingon_10min.csv  AlgorithmA       ON            10   \n",
       "2    algorithmb_gmappingoff_2min.csv  AlgorithmB      OFF             2   \n",
       "10   algorithmb_gmappingoff_5min.csv  AlgorithmB      OFF             5   \n",
       "11  algorithmb_gmappingoff_10min.csv  AlgorithmB      OFF            10   \n",
       "3     algorithmb_gmappingon_2min.csv  AlgorithmB       ON             2   \n",
       "9     algorithmb_gmappingon_5min.csv  AlgorithmB       ON             5   \n",
       "4    algorithmb_gmappingon_10min.csv  AlgorithmB       ON            10   \n",
       "\n",
       "    rmse_error  mae_error  max_error   cpu_mean  memory_mean  \n",
       "7     0.093685   0.083453   0.207659  28.058656   390.366364  \n",
       "1     0.218408   0.191426   0.429640  28.523656   384.248801  \n",
       "0     0.428548   0.373248   0.773025  28.143886   380.305109  \n",
       "6     0.049956   0.045292   0.102950  35.009435   430.102479  \n",
       "5     0.111942   0.098839   0.210905  35.565945   424.342170  \n",
       "8     0.217239   0.190038   0.389361  35.123617   420.364987  \n",
       "2     0.148677   0.133288   0.313018  32.005446   402.789335  \n",
       "10    0.332668   0.292338   0.626400  32.744006   395.336306  \n",
       "11    0.648087   0.565424   1.175991  32.121463   390.364294  \n",
       "3     0.083354   0.075870   0.158725  40.070506   463.065771  \n",
       "9     0.183181   0.162406   0.333666  40.746644   455.533681  \n",
       "4     0.351066   0.307841   0.635364  40.131652   450.300213  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = summarize_all_runs(DATA_DIR)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e146116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.387824Z",
     "iopub.status.busy": "2025-11-30T13:27:18.387495Z",
     "iopub.status.idle": "2025-11-30T13:27:18.402282Z",
     "shell.execute_reply": "2025-11-30T13:27:18.400984Z"
    },
    "papermill": {
     "duration": 0.021781,
     "end_time": "2025-11-30T13:27:18.404292",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.382511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MemoryStore:\n",
    "    \"\"\"Very simple in-notebook memory for past queries & results.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def add_entry(self, question: str, result: dict):\n",
    "        self.history.append({\"question\": question, \"result\": result})\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "\n",
    "class DataAnalysisAgent:\n",
    "    def __init__(self, summary_df: pd.DataFrame):\n",
    "        self.summary_df = summary_df\n",
    "\n",
    "    def get_min_rmse(self):\n",
    "        idx = self.summary_df[\"rmse_error\"].idxmin()\n",
    "        return self.summary_df.loc[idx].to_dict()\n",
    "\n",
    "    def filter_by_gmapping(self, state: str):\n",
    "        return self.summary_df[self.summary_df[\"gmapping\"] == state].copy()\n",
    "\n",
    "    def filter_by_duration(self, minutes: int):\n",
    "        return self.summary_df[self.summary_df[\"duration_min\"] == minutes].copy()\n",
    "\n",
    "\n",
    "class ExplanationAgent:\n",
    "    def explain_best_config(self, best_row: dict) -> str:\n",
    "        return (\n",
    "            f\"The best configuration by RMSE is {best_row['algorithm']} with \"\n",
    "            f\"Gmapping {best_row['gmapping']} for {best_row['duration_min']} minutes.\\n\"\n",
    "            f\"RMSE = {best_row['rmse_error']:.4f} m, \"\n",
    "            f\"MAE = {best_row['mae_error']:.4f} m, \"\n",
    "            f\"CPU ≈ {best_row['cpu_mean']:.1f}%, \"\n",
    "            f\"Memory ≈ {best_row['memory_mean']:.1f} MB.\"\n",
    "        )\n",
    "\n",
    "    def explain_gmapping_effect(self, df_on: pd.DataFrame, df_off: pd.DataFrame, duration: int) -> str:\n",
    "        mean_on = df_on[\"rmse_error\"].mean()\n",
    "        mean_off = df_off[\"rmse_error\"].mean()\n",
    "        diff = mean_off - mean_on\n",
    "        direction = \"lower\" if diff > 0 else \"higher\"\n",
    "        return (\n",
    "            f\"For {duration}-minute runs, Gmapping ON yields average RMSE of {mean_on:.4f} m, \"\n",
    "            f\"while Gmapping OFF yields {mean_off:.4f} m. \"\n",
    "            f\"That means Gmapping ON has {abs(diff):.4f} m {direction} error on average.\"\n",
    "        )\n",
    "\n",
    "\n",
    "class OrchestratorAgent:\n",
    "    def __init__(self, summary_df: pd.DataFrame):\n",
    "        self.memory = MemoryStore()\n",
    "        self.analysis_agent = DataAnalysisAgent(summary_df)\n",
    "        self.explainer = ExplanationAgent()\n",
    "\n",
    "    def answer(self, question: str) -> str:\n",
    "        question_lower = question.lower()\n",
    "\n",
    "        if \"minimum localization error\" in question_lower or \"lowest rmse\" in question_lower:\n",
    "            best = self.analysis_agent.get_min_rmse()\n",
    "            text = self.explainer.explain_best_config(best)\n",
    "            self.memory.add_entry(question, {\"best_config\": best})\n",
    "            return text\n",
    "\n",
    "        if \"gmapping\" in question_lower and \"10 min\" in question_lower or \"10-minute\" in question_lower:\n",
    "            df_on = self.analysis_agent.filter_by_gmapping(\"ON\")\n",
    "            df_on = df_on[df_on[\"duration_min\"] == 10]\n",
    "            df_off = self.analysis_agent.filter_by_gmapping(\"OFF\")\n",
    "            df_off = df_off[df_off[\"duration_min\"] == 10]\n",
    "            text = self.explainer.explain_gmapping_effect(df_on, df_off, duration=10)\n",
    "            self.memory.add_entry(question, {\"gmapping_on\": df_on.to_dict(), \"gmapping_off\": df_off.to_dict()})\n",
    "            return text\n",
    "\n",
    "        return \"I understand your question, but this prototype currently supports only a small set of query types (best configuration, Gmapping vs non-Gmapping).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf62c937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.413171Z",
     "iopub.status.busy": "2025-11-30T13:27:18.412808Z",
     "iopub.status.idle": "2025-11-30T13:27:18.428669Z",
     "shell.execute_reply": "2025-11-30T13:27:18.427399Z"
    },
    "papermill": {
     "duration": 0.02276,
     "end_time": "2025-11-30T13:27:18.430714",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.407954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best configuration by RMSE is AlgorithmA with Gmapping ON for 2 minutes.\n",
      "RMSE = 0.0500 m, MAE = 0.0453 m, CPU ≈ 35.0%, Memory ≈ 430.1 MB.\n",
      "\n",
      "For 10-minute runs, Gmapping ON yields average RMSE of 0.2842 m, while Gmapping OFF yields 0.5383 m. That means Gmapping ON has 0.2542 m lower error on average.\n"
     ]
    }
   ],
   "source": [
    "agent = OrchestratorAgent(summary_df)\n",
    "\n",
    "print(agent.answer(\"Which configuration has the minimum localization error?\"))\n",
    "print()\n",
    "print(agent.answer(\"How does Gmapping affect localization for 10-minute runs?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f4833",
   "metadata": {
    "papermill": {
     "duration": 0.003692,
     "end_time": "2025-11-30T13:27:18.438062",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.434370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Multi-Agent Architecture\n",
    "\n",
    "The analysis above is fully deterministic and reproducible. \n",
    "On top of this, we build a simple multi-agent layer that separates:\n",
    "\n",
    "- **DataAnalysisAgent** — queries the summary table, filters configurations, finds best runs.  \n",
    "- **ExplanationAgent** — turns numeric results into human-readable text.  \n",
    "- **MemoryStore** — retains past questions and results to support iterative analysis.  \n",
    "- **OrchestratorAgent** — interprets high-level questions and delegates to the other agents.\n",
    "\n",
    "This pattern mirrors how a human researcher might work with an assistant: \n",
    "the assistant looks up numbers, compares experiments, and then explains the outcome, \n",
    "while the researcher keeps asking follow-up questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3160fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.447377Z",
     "iopub.status.busy": "2025-11-30T13:27:18.447071Z",
     "iopub.status.idle": "2025-11-30T13:27:18.460900Z",
     "shell.execute_reply": "2025-11-30T13:27:18.460011Z"
    },
    "papermill": {
     "duration": 0.02054,
     "end_time": "2025-11-30T13:27:18.462352",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.441812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MemoryStore:\n",
    "    \"\"\"Simple in-notebook memory for past queries and results.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def add_entry(self, question: str, result: dict):\n",
    "        self.history.append({\"question\": question, \"result\": result})\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "\n",
    "class DataAnalysisAgent:\n",
    "    def __init__(self, summary_df: pd.DataFrame):\n",
    "        self.summary_df = summary_df\n",
    "\n",
    "    def get_min_rmse(self) -> dict:\n",
    "        idx = self.summary_df[\"rmse_error\"].idxmin()\n",
    "        return self.summary_df.loc[idx].to_dict()\n",
    "\n",
    "    def filter_by_gmapping_and_duration(self, gmapping_state: str, duration_min: int) -> pd.DataFrame:\n",
    "        return self.summary_df[\n",
    "            (self.summary_df[\"gmapping\"] == gmapping_state) &\n",
    "            (self.summary_df[\"duration_min\"] == duration_min)\n",
    "        ].copy()\n",
    "\n",
    "\n",
    "class ExplanationAgent:\n",
    "    def explain_best_config(self, best_row: dict) -> str:\n",
    "        return (\n",
    "            f\"The best configuration by RMSE is {best_row['algorithm']} \"\n",
    "            f\"with Gmapping {best_row['gmapping']} for {int(best_row['duration_min'])} minutes.\\n\"\n",
    "            f\"RMSE = {best_row['rmse_error']:.4f} m, \"\n",
    "            f\"MAE = {best_row['mae_error']:.4f} m, \"\n",
    "            f\"max error = {best_row['max_error']:.4f} m,\\n\"\n",
    "            f\"CPU ≈ {best_row['cpu_mean']:.1f}%, \"\n",
    "            f\"Memory ≈ {best_row['memory_mean']:.1f} MB.\"\n",
    "        )\n",
    "\n",
    "    def explain_gmapping_effect(self, df_on: pd.DataFrame, df_off: pd.DataFrame, duration: int) -> str:\n",
    "        if df_on.empty or df_off.empty:\n",
    "            return f\"No matching runs found for {duration}-minute duration.\"\n",
    "\n",
    "        mean_on = df_on[\"rmse_error\"].mean()\n",
    "        mean_off = df_off[\"rmse_error\"].mean()\n",
    "        diff = mean_off - mean_on\n",
    "        if diff > 0:\n",
    "            direction = \"lower\"\n",
    "        elif diff < 0:\n",
    "            direction = \"higher\"\n",
    "        else:\n",
    "            direction = \"the same\"\n",
    "\n",
    "        return (\n",
    "            f\"For {duration}-minute runs:\\n\"\n",
    "            f\"- Gmapping ON:  average RMSE = {mean_on:.4f} m\\n\"\n",
    "            f\"- Gmapping OFF: average RMSE = {mean_off:.4f} m\\n\\n\"\n",
    "            f\"On average, Gmapping ON shows {abs(diff):.4f} m {direction} error compared to Gmapping OFF.\"\n",
    "        )\n",
    "\n",
    "\n",
    "class OrchestratorAgent:\n",
    "    \"\"\"\n",
    "    Very simple natural-language router.\n",
    "    In a production deployment, this could be powered by Gemini to interpret\n",
    "    arbitrary questions and decide which tools/agents to call.\n",
    "    \"\"\"\n",
    "    def __init__(self, summary_df: pd.DataFrame):\n",
    "        self.memory = MemoryStore()\n",
    "        self.analysis_agent = DataAnalysisAgent(summary_df)\n",
    "        self.explainer = ExplanationAgent()\n",
    "\n",
    "    def answer(self, question: str) -> str:\n",
    "        q = question.lower()\n",
    "\n",
    "        # Query 1: best / minimum localization error\n",
    "        if \"minimum localization error\" in q or \"lowest rmse\" in q or \"best configuration\" in q:\n",
    "            best = self.analysis_agent.get_min_rmse()\n",
    "            text = self.explainer.explain_best_config(best)\n",
    "            self.memory.add_entry(question, {\"best_config\": best})\n",
    "            return text\n",
    "\n",
    "        # Query 2: gmapping effect for 10-minute runs\n",
    "        if \"gmapping\" in q and \"10\" in q:\n",
    "            df_on = self.analysis_agent.filter_by_gmapping_and_duration(\"ON\", 10)\n",
    "            df_off = self.analysis_agent.filter_by_gmapping_and_duration(\"OFF\", 10)\n",
    "            text = self.explainer.explain_gmapping_effect(df_on, df_off, duration=10)\n",
    "            self.memory.add_entry(question, {\"gmapping_on\": df_on.to_dict(), \"gmapping_off\": df_off.to_dict()})\n",
    "            return text\n",
    "\n",
    "        # Fallback\n",
    "        return (\n",
    "            \"I understand your question, but this prototype currently supports only a small set of \"\n",
    "            \"query types, such as:\\n\"\n",
    "            \"- 'Which configuration has the minimum localization error?'\\n\"\n",
    "            \"- 'How does Gmapping affect localization for 10-minute runs?'\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5221329b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:27:18.470863Z",
     "iopub.status.busy": "2025-11-30T13:27:18.470565Z",
     "iopub.status.idle": "2025-11-30T13:27:18.481395Z",
     "shell.execute_reply": "2025-11-30T13:27:18.480210Z"
    },
    "papermill": {
     "duration": 0.017027,
     "end_time": "2025-11-30T13:27:18.482959",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.465932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Which configuration has the minimum localization error?\n",
      "\n",
      "The best configuration by RMSE is AlgorithmA with Gmapping ON for 2 minutes.\n",
      "RMSE = 0.0500 m, MAE = 0.0453 m, max error = 0.1030 m,\n",
      "CPU ≈ 35.0%, Memory ≈ 430.1 MB.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Q2: How does Gmapping affect localization for 10-minute runs?\n",
      "\n",
      "For 10-minute runs:\n",
      "- Gmapping ON:  average RMSE = 0.2842 m\n",
      "- Gmapping OFF: average RMSE = 0.5383 m\n",
      "\n",
      "On average, Gmapping ON shows 0.2542 m lower error compared to Gmapping OFF.\n"
     ]
    }
   ],
   "source": [
    "agent = OrchestratorAgent(summary_df)\n",
    "\n",
    "print(\"Q1: Which configuration has the minimum localization error?\\n\")\n",
    "print(agent.answer(\"Which configuration has the minimum localization error?\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Q2: How does Gmapping affect localization for 10-minute runs?\\n\")\n",
    "print(agent.answer(\"How does Gmapping affect localization for 10-minute runs?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb8ecf",
   "metadata": {
    "papermill": {
     "duration": 0.003414,
     "end_time": "2025-11-30T13:27:18.489962",
     "exception": false,
     "start_time": "2025-11-30T13:27:18.486548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Demo: Conversational Analysis over Synthetic TB3 Experiments\n",
    "\n",
    "Below, we query the OrchestratorAgent using natural language instructions:\n",
    "\n",
    "1. *“Which configuration has the minimum localization error?”*  \n",
    "2. *“How does Gmapping affect localization for 10-minute runs?”*\n",
    "\n",
    "The Orchestrator delegates numeric work to the `DataAnalysisAgent`, \n",
    "which calculates localization metrics directly from the CSV logs. \n",
    "The `ExplanationAgent` translates the results into concise insights, \n",
    "while interaction history is stored in the `MemoryStore` to support follow-up queries.\n",
    "\n",
    "The current prototype uses deterministic Python tools to compute metrics such as RMSE, MAE, \n",
    "and CPU/memory averages. These computations remain transparent and reproducible — a requirement in robotics research.\n",
    "\n",
    "In a production deployment, the orchestration and conversational layers would be powered by \n",
    "Gemini Agents, enabling:\n",
    "- multi-step reasoning over large experiment sets,\n",
    "- richer natural language interaction,\n",
    "- and persistent memory across research sessions.\n",
    "\n",
    "This hybrid design ensures that scientific evaluation remains grounded in deterministic computation, \n",
    "while leveraging LLM agents for interpretation, question decomposition, and experiment guidance.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    },
    {
     "datasetId": 8875541,
     "sourceId": 13928027,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.434017,
   "end_time": "2025-11-30T13:27:19.012579",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T13:27:10.578562",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
