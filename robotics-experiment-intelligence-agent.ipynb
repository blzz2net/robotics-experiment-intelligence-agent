{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"},{"sourceId":13928027,"sourceType":"datasetVersion","datasetId":8875541}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Robotics Experiment Intelligence Agent\n\nThis notebook implements an Enterprise-style Experiment Intelligence Agent for robotics research. \nThe agent ingests synthetic TurtleBot3 experiment logs, computes localization metrics, compares navigation configurations, \nand answers research questions without manual spreadsheet analysis.\n\nInstead of manually parsing ROS data, aligning trajectories, and calculating RMSE or CPU usage across runs, \nthe system uses a multi-agent architecture:\n\n- **OrchestratorAgent** — Understands what the user wants\n- **DataAnalysisAgent** — Deterministic metrics computation from CSV logs\n- **ExplanationAgent**  — Converts numeric results into human-readable insights  \n- **MemoryStore**       — Preserves context across queries for iterative analysis\n\nAll quantitative evaluation (RMSE, MAE, peak error, CPU/memory) is computed transparently using Python and remains reproducible.  \nThe agent layer adds reasoning and interactivity, similar to a research assistant, allowing the user to ask questions such as:\n\n> “Which configuration achieved the lowest localization error across all runs?”\n\nor\n\n> “How does Gmapping affect performance for 10-minute missions?”\n\nThis notebook demonstrates the prototype using synthetic TurtleBot3 runs at 5 Hz across four configurations and three durations.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n!ls /kaggle/input\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:17.878493Z","iopub.execute_input":"2025-12-01T02:30:17.878906Z","iopub.status.idle":"2025-12-01T02:30:18.351550Z","shell.execute_reply.started":"2025-12-01T02:30:17.878878Z","shell.execute_reply":"2025-12-01T02:30:18.350193Z"}},"outputs":[{"name":"stdout","text":"agents-intensive-capstone-project  synthetic-tb3-experiments-for-agent-analysis\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pathlib import Path\n\nDATA_DIR = Path(\"/kaggle/input/synthetic-tb3-experiments-for-agent-analysis\")\n\n!ls \"$DATA_DIR\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.353685Z","iopub.execute_input":"2025-12-01T02:30:18.354428Z","iopub.status.idle":"2025-12-01T02:30:18.489681Z","shell.execute_reply.started":"2025-12-01T02:30:18.354396Z","shell.execute_reply":"2025-12-01T02:30:18.488400Z"}},"outputs":[{"name":"stdout","text":"algorithma_gmappingoff_10min.csv  algorithmb_gmappingoff_10min.csv\nalgorithma_gmappingoff_2min.csv   algorithmb_gmappingoff_2min.csv\nalgorithma_gmappingoff_5min.csv   algorithmb_gmappingoff_5min.csv\nalgorithma_gmappingon_10min.csv   algorithmb_gmappingon_10min.csv\nalgorithma_gmappingon_2min.csv\t  algorithmb_gmappingon_2min.csv\nalgorithma_gmappingon_5min.csv\t  algorithmb_gmappingon_5min.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\ndef load_run(file_path: Path) -> pd.DataFrame:\n    \"\"\"Load a single experiment CSV and validate columns.\"\"\"\n    df = pd.read_csv(file_path)\n    required_cols = [\"timestamp\", \"x\", \"y\", \"x_gt\", \"y_gt\", \"v_linear\", \"v_angular\", \"cpu\", \"memory\"]\n    missing = [c for c in required_cols if c not in df.columns]\n    if missing:\n        raise ValueError(f\"Missing columns in {file_path}: {missing}\")\n    return df\n\ndef parse_config_from_name(filename: str) -> dict:\n    \"\"\"\n    Parse config info from filename pattern:\n    algorithma_gmappingon_5min.csv\n    \"\"\"\n    base = Path(filename).stem.lower()  \n    parts = base.split(\"_\")\n\n    if len(parts) < 3:\n        raise ValueError(f\"Unexpected filename pattern: {filename}\")\n\n    algo_raw = parts[0]   # 'algorithma'\n    gmap_raw = parts[1]   # 'gmappingon'\n    dur_raw  = parts[2]   # '5min'\n\n    algo_letter = algo_raw.replace(\"algorithm\", \"\").upper()  # 'A' or 'B'\n    gmapping    = \"ON\" if \"on\" in gmap_raw else \"OFF\"\n    duration    = int(dur_raw.replace(\"min\", \"\").strip())\n\n    return {\n        \"algorithm\": f\"Algorithm{algo_letter}\",\n        \"gmapping\": gmapping,\n        \"duration_min\": duration,\n    }\n\ndef compute_localization_metrics(df: pd.DataFrame) -> dict:\n    \"\"\"Compute localization + resource metrics for one run.\"\"\"\n    dx = df[\"x\"] - df[\"x_gt\"]\n    dy = df[\"y\"] - df[\"y_gt\"]\n    err = np.sqrt(dx**2 + dy**2)\n\n    rmse = float(np.sqrt(np.mean(err**2)))\n    mae  = float(np.mean(np.abs(err)))\n    max_err = float(np.max(err))\n\n    cpu_mean = float(df[\"cpu\"].mean())\n    mem_mean = float(df[\"memory\"].mean())\n\n    return {\n        \"rmse_error\": rmse,\n        \"mae_error\": mae,\n        \"max_error\": max_err,\n        \"cpu_mean\": cpu_mean,\n        \"memory_mean\": mem_mean,\n    }\n\ndef summarize_all_runs(data_dir: Path) -> pd.DataFrame:\n    \"\"\"Scan CSVs in data_dir and build a summary table with config + metrics.\"\"\"\n    rows = []\n    for csv_path in data_dir.glob(\"*.csv\"):\n        name_lower = csv_path.name.lower()\n        # Only process files that look like our experiment logs\n        if not name_lower.startswith(\"algorithma_\") and not name_lower.startswith(\"algorithmb_\"):\n            continue\n\n        df = load_run(csv_path)\n        cfg = parse_config_from_name(csv_path.name)\n        metrics = compute_localization_metrics(df)\n\n        row = {\n            \"file\": csv_path.name,\n            **cfg,\n            **metrics,\n        }\n        rows.append(row)\n\n    summary_df = pd.DataFrame(rows)\n    if summary_df.empty:\n        raise RuntimeError(f\"No valid experiment CSVs found in {data_dir}\")\n\n    return summary_df.sort_values([\"algorithm\", \"gmapping\", \"duration_min\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.490976Z","iopub.execute_input":"2025-12-01T02:30:18.491231Z","iopub.status.idle":"2025-12-01T02:30:18.505768Z","shell.execute_reply.started":"2025-12-01T02:30:18.491207Z","shell.execute_reply":"2025-12-01T02:30:18.504637Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"summary_df = summarize_all_runs(DATA_DIR)\nsummary_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.506908Z","iopub.execute_input":"2025-12-01T02:30:18.507151Z","iopub.status.idle":"2025-12-01T02:30:18.765230Z","shell.execute_reply.started":"2025-12-01T02:30:18.507131Z","shell.execute_reply":"2025-12-01T02:30:18.764316Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                file   algorithm gmapping  duration_min  \\\n7    algorithma_gmappingoff_2min.csv  AlgorithmA      OFF             2   \n1    algorithma_gmappingoff_5min.csv  AlgorithmA      OFF             5   \n0   algorithma_gmappingoff_10min.csv  AlgorithmA      OFF            10   \n6     algorithma_gmappingon_2min.csv  AlgorithmA       ON             2   \n5     algorithma_gmappingon_5min.csv  AlgorithmA       ON             5   \n8    algorithma_gmappingon_10min.csv  AlgorithmA       ON            10   \n2    algorithmb_gmappingoff_2min.csv  AlgorithmB      OFF             2   \n10   algorithmb_gmappingoff_5min.csv  AlgorithmB      OFF             5   \n11  algorithmb_gmappingoff_10min.csv  AlgorithmB      OFF            10   \n3     algorithmb_gmappingon_2min.csv  AlgorithmB       ON             2   \n9     algorithmb_gmappingon_5min.csv  AlgorithmB       ON             5   \n4    algorithmb_gmappingon_10min.csv  AlgorithmB       ON            10   \n\n    rmse_error  mae_error  max_error   cpu_mean  memory_mean  \n7     0.093685   0.083453   0.207659  28.058656   390.366364  \n1     0.218408   0.191426   0.429640  28.523656   384.248801  \n0     0.428548   0.373248   0.773025  28.143886   380.305109  \n6     0.049956   0.045292   0.102950  35.009435   430.102479  \n5     0.111942   0.098839   0.210905  35.565945   424.342170  \n8     0.217239   0.190038   0.389361  35.123617   420.364987  \n2     0.148677   0.133288   0.313018  32.005446   402.789335  \n10    0.332668   0.292338   0.626400  32.744006   395.336306  \n11    0.648087   0.565424   1.175991  32.121463   390.364294  \n3     0.083354   0.075870   0.158725  40.070506   463.065771  \n9     0.183181   0.162406   0.333666  40.746644   455.533681  \n4     0.351066   0.307841   0.635364  40.131652   450.300213  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>algorithm</th>\n      <th>gmapping</th>\n      <th>duration_min</th>\n      <th>rmse_error</th>\n      <th>mae_error</th>\n      <th>max_error</th>\n      <th>cpu_mean</th>\n      <th>memory_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>algorithma_gmappingoff_2min.csv</td>\n      <td>AlgorithmA</td>\n      <td>OFF</td>\n      <td>2</td>\n      <td>0.093685</td>\n      <td>0.083453</td>\n      <td>0.207659</td>\n      <td>28.058656</td>\n      <td>390.366364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>algorithma_gmappingoff_5min.csv</td>\n      <td>AlgorithmA</td>\n      <td>OFF</td>\n      <td>5</td>\n      <td>0.218408</td>\n      <td>0.191426</td>\n      <td>0.429640</td>\n      <td>28.523656</td>\n      <td>384.248801</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>algorithma_gmappingoff_10min.csv</td>\n      <td>AlgorithmA</td>\n      <td>OFF</td>\n      <td>10</td>\n      <td>0.428548</td>\n      <td>0.373248</td>\n      <td>0.773025</td>\n      <td>28.143886</td>\n      <td>380.305109</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>algorithma_gmappingon_2min.csv</td>\n      <td>AlgorithmA</td>\n      <td>ON</td>\n      <td>2</td>\n      <td>0.049956</td>\n      <td>0.045292</td>\n      <td>0.102950</td>\n      <td>35.009435</td>\n      <td>430.102479</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>algorithma_gmappingon_5min.csv</td>\n      <td>AlgorithmA</td>\n      <td>ON</td>\n      <td>5</td>\n      <td>0.111942</td>\n      <td>0.098839</td>\n      <td>0.210905</td>\n      <td>35.565945</td>\n      <td>424.342170</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>algorithma_gmappingon_10min.csv</td>\n      <td>AlgorithmA</td>\n      <td>ON</td>\n      <td>10</td>\n      <td>0.217239</td>\n      <td>0.190038</td>\n      <td>0.389361</td>\n      <td>35.123617</td>\n      <td>420.364987</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>algorithmb_gmappingoff_2min.csv</td>\n      <td>AlgorithmB</td>\n      <td>OFF</td>\n      <td>2</td>\n      <td>0.148677</td>\n      <td>0.133288</td>\n      <td>0.313018</td>\n      <td>32.005446</td>\n      <td>402.789335</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>algorithmb_gmappingoff_5min.csv</td>\n      <td>AlgorithmB</td>\n      <td>OFF</td>\n      <td>5</td>\n      <td>0.332668</td>\n      <td>0.292338</td>\n      <td>0.626400</td>\n      <td>32.744006</td>\n      <td>395.336306</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>algorithmb_gmappingoff_10min.csv</td>\n      <td>AlgorithmB</td>\n      <td>OFF</td>\n      <td>10</td>\n      <td>0.648087</td>\n      <td>0.565424</td>\n      <td>1.175991</td>\n      <td>32.121463</td>\n      <td>390.364294</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>algorithmb_gmappingon_2min.csv</td>\n      <td>AlgorithmB</td>\n      <td>ON</td>\n      <td>2</td>\n      <td>0.083354</td>\n      <td>0.075870</td>\n      <td>0.158725</td>\n      <td>40.070506</td>\n      <td>463.065771</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>algorithmb_gmappingon_5min.csv</td>\n      <td>AlgorithmB</td>\n      <td>ON</td>\n      <td>5</td>\n      <td>0.183181</td>\n      <td>0.162406</td>\n      <td>0.333666</td>\n      <td>40.746644</td>\n      <td>455.533681</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>algorithmb_gmappingon_10min.csv</td>\n      <td>AlgorithmB</td>\n      <td>ON</td>\n      <td>10</td>\n      <td>0.351066</td>\n      <td>0.307841</td>\n      <td>0.635364</td>\n      <td>40.131652</td>\n      <td>450.300213</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"class MemoryStore:\n    \"\"\"Very simple in-notebook memory for past queries & results.\"\"\"\n    def __init__(self):\n        self.history = []\n\n    def add_entry(self, question: str, result: dict):\n        self.history.append({\"question\": question, \"result\": result})\n\n    def get_history(self):\n        return self.history\n\n\nclass DataAnalysisAgent:\n    def __init__(self, summary_df: pd.DataFrame):\n        self.summary_df = summary_df\n\n    def get_min_rmse(self):\n        idx = self.summary_df[\"rmse_error\"].idxmin()\n        return self.summary_df.loc[idx].to_dict()\n\n    def filter_by_gmapping(self, state: str):\n        return self.summary_df[self.summary_df[\"gmapping\"] == state].copy()\n\n    def filter_by_duration(self, minutes: int):\n        return self.summary_df[self.summary_df[\"duration_min\"] == minutes].copy()\n\n\nclass ExplanationAgent:\n    def explain_best_config(self, best_row: dict) -> str:\n        return (\n            f\"The best configuration by RMSE is {best_row['algorithm']} with \"\n            f\"Gmapping {best_row['gmapping']} for {best_row['duration_min']} minutes.\\n\"\n            f\"RMSE = {best_row['rmse_error']:.4f} m, \"\n            f\"MAE = {best_row['mae_error']:.4f} m, \"\n            f\"CPU ≈ {best_row['cpu_mean']:.1f}%, \"\n            f\"Memory ≈ {best_row['memory_mean']:.1f} MB.\"\n        )\n\n    def explain_gmapping_effect(self, df_on: pd.DataFrame, df_off: pd.DataFrame, duration: int) -> str:\n        mean_on = df_on[\"rmse_error\"].mean()\n        mean_off = df_off[\"rmse_error\"].mean()\n        diff = mean_off - mean_on\n        direction = \"lower\" if diff > 0 else \"higher\"\n        return (\n            f\"For {duration}-minute runs, Gmapping ON yields average RMSE of {mean_on:.4f} m, \"\n            f\"while Gmapping OFF yields {mean_off:.4f} m. \"\n            f\"That means Gmapping ON has {abs(diff):.4f} m {direction} error on average.\"\n        )\n\n\nclass OrchestratorAgent:\n    def __init__(self, summary_df: pd.DataFrame):\n        self.memory = MemoryStore()\n        self.analysis_agent = DataAnalysisAgent(summary_df)\n        self.explainer = ExplanationAgent()\n\n    def answer(self, question: str) -> str:\n        question_lower = question.lower()\n\n        if \"minimum localization error\" in question_lower or \"lowest rmse\" in question_lower:\n            best = self.analysis_agent.get_min_rmse()\n            text = self.explainer.explain_best_config(best)\n            self.memory.add_entry(question, {\"best_config\": best})\n            return text\n\n        if \"gmapping\" in question_lower and \"10 min\" in question_lower or \"10-minute\" in question_lower:\n            df_on = self.analysis_agent.filter_by_gmapping(\"ON\")\n            df_on = df_on[df_on[\"duration_min\"] == 10]\n            df_off = self.analysis_agent.filter_by_gmapping(\"OFF\")\n            df_off = df_off[df_off[\"duration_min\"] == 10]\n            text = self.explainer.explain_gmapping_effect(df_on, df_off, duration=10)\n            self.memory.add_entry(question, {\"gmapping_on\": df_on.to_dict(), \"gmapping_off\": df_off.to_dict()})\n            return text\n\n        return \"I understand your question, but this prototype currently supports only a small set of query types (best configuration, Gmapping vs non-Gmapping).\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.767649Z","iopub.execute_input":"2025-12-01T02:30:18.768003Z","iopub.status.idle":"2025-12-01T02:30:18.787491Z","shell.execute_reply.started":"2025-12-01T02:30:18.767972Z","shell.execute_reply":"2025-12-01T02:30:18.786489Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"agent = OrchestratorAgent(summary_df)\n\nprint(agent.answer(\"Which configuration has the minimum localization error?\"))\nprint()\nprint(agent.answer(\"How does Gmapping affect localization for 10-minute runs?\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.788717Z","iopub.execute_input":"2025-12-01T02:30:18.789056Z","iopub.status.idle":"2025-12-01T02:30:18.832773Z","shell.execute_reply.started":"2025-12-01T02:30:18.789027Z","shell.execute_reply":"2025-12-01T02:30:18.831761Z"}},"outputs":[{"name":"stdout","text":"The best configuration by RMSE is AlgorithmA with Gmapping ON for 2 minutes.\nRMSE = 0.0500 m, MAE = 0.0453 m, CPU ≈ 35.0%, Memory ≈ 430.1 MB.\n\nFor 10-minute runs, Gmapping ON yields average RMSE of 0.2842 m, while Gmapping OFF yields 0.5383 m. That means Gmapping ON has 0.2542 m lower error on average.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Multi-Agent Architecture\n\nThe analysis above is fully deterministic and reproducible. \nOn top of this, we build a simple multi-agent layer that separates:\n\n- **OrchestratorAgent** — Interprets high-level questions and delegates to the other agents.\n- **DataAnalysisAgent** — Queries the summary table, filters configurations, finds best runs.  \n- **ExplanationAgent** — Turns numeric results into human-readable text.  \n- **MemoryStore** — Retains past questions and results to support iterative analysis.\n  \nThis pattern mirrors how a human researcher might work with an assistant: \nthe assistant looks up numbers, compares experiments, and then explains the outcome, \nwhile the researcher keeps asking follow-up questions.\n\n","metadata":{}},{"cell_type":"code","source":"class MemoryStore:\n    \"\"\"Simple in-notebook memory for past queries and results.\"\"\"\n    def __init__(self):\n        self.history = []\n\n    def add_entry(self, question: str, result: dict):\n        self.history.append({\"question\": question, \"result\": result})\n\n    def get_history(self):\n        return self.history\n\n\nclass DataAnalysisAgent:\n    def __init__(self, summary_df: pd.DataFrame):\n        self.summary_df = summary_df\n\n    def get_min_rmse(self) -> dict:\n        idx = self.summary_df[\"rmse_error\"].idxmin()\n        return self.summary_df.loc[idx].to_dict()\n\n    def filter_by_gmapping_and_duration(self, gmapping_state: str, duration_min: int) -> pd.DataFrame:\n        return self.summary_df[\n            (self.summary_df[\"gmapping\"] == gmapping_state) &\n            (self.summary_df[\"duration_min\"] == duration_min)\n        ].copy()\n\n\nclass ExplanationAgent:\n    def explain_best_config(self, best_row: dict) -> str:\n        return (\n            f\"The best configuration by RMSE is {best_row['algorithm']} \"\n            f\"with Gmapping {best_row['gmapping']} for {int(best_row['duration_min'])} minutes.\\n\"\n            f\"RMSE = {best_row['rmse_error']:.4f} m, \"\n            f\"MAE = {best_row['mae_error']:.4f} m, \"\n            f\"max error = {best_row['max_error']:.4f} m,\\n\"\n            f\"CPU ≈ {best_row['cpu_mean']:.1f}%, \"\n            f\"Memory ≈ {best_row['memory_mean']:.1f} MB.\"\n        )\n\n    def explain_gmapping_effect(self, df_on: pd.DataFrame, df_off: pd.DataFrame, duration: int) -> str:\n        if df_on.empty or df_off.empty:\n            return f\"No matching runs found for {duration}-minute duration.\"\n\n        mean_on = df_on[\"rmse_error\"].mean()\n        mean_off = df_off[\"rmse_error\"].mean()\n        diff = mean_off - mean_on\n        if diff > 0:\n            direction = \"lower\"\n        elif diff < 0:\n            direction = \"higher\"\n        else:\n            direction = \"the same\"\n\n        return (\n            f\"For {duration}-minute runs:\\n\"\n            f\"- Gmapping ON:  average RMSE = {mean_on:.4f} m\\n\"\n            f\"- Gmapping OFF: average RMSE = {mean_off:.4f} m\\n\\n\"\n            f\"On average, Gmapping ON shows {abs(diff):.4f} m {direction} error compared to Gmapping OFF.\"\n        )\n\n\nclass OrchestratorAgent:\n    \"\"\"\n    Very simple natural-language router.\n    In a production deployment, this could be powered by Gemini to interpret\n    arbitrary questions and decide which tools/agents to call.\n    \"\"\"\n    def __init__(self, summary_df: pd.DataFrame):\n        self.memory = MemoryStore()\n        self.analysis_agent = DataAnalysisAgent(summary_df)\n        self.explainer = ExplanationAgent()\n\n    def answer(self, question: str) -> str:\n        q = question.lower()\n\n        # Query 1: best / minimum localization error\n        if \"minimum localization error\" in q or \"lowest rmse\" in q or \"best configuration\" in q:\n            best = self.analysis_agent.get_min_rmse()\n            text = self.explainer.explain_best_config(best)\n            self.memory.add_entry(question, {\"best_config\": best})\n            return text\n\n        # Query 2: gmapping effect for 10-minute runs\n        if \"gmapping\" in q and \"10\" in q:\n            df_on = self.analysis_agent.filter_by_gmapping_and_duration(\"ON\", 10)\n            df_off = self.analysis_agent.filter_by_gmapping_and_duration(\"OFF\", 10)\n            text = self.explainer.explain_gmapping_effect(df_on, df_off, duration=10)\n            self.memory.add_entry(question, {\"gmapping_on\": df_on.to_dict(), \"gmapping_off\": df_off.to_dict()})\n            return text\n\n        # Fallback\n        return (\n            \"I understand your question, but this prototype currently supports only a small set of \"\n            \"query types, such as:\\n\"\n            \"- 'Which configuration has the minimum localization error?'\\n\"\n            \"- 'How does Gmapping affect localization for 10-minute runs?'\"\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.833988Z","iopub.execute_input":"2025-12-01T02:30:18.834343Z","iopub.status.idle":"2025-12-01T02:30:18.856117Z","shell.execute_reply.started":"2025-12-01T02:30:18.834277Z","shell.execute_reply":"2025-12-01T02:30:18.854942Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"agent = OrchestratorAgent(summary_df)\n\nprint(\"Q1: Which configuration has the minimum localization error?\\n\")\nprint(agent.answer(\"Which configuration has the minimum localization error?\"))\n\nprint(\"\\n\" + \"=\"*80 + \"\\n\")\n\nprint(\"Q2: How does Gmapping affect localization for 10-minute runs?\\n\")\nprint(agent.answer(\"How does Gmapping affect localization for 10-minute runs?\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:30:18.857553Z","iopub.execute_input":"2025-12-01T02:30:18.858046Z","iopub.status.idle":"2025-12-01T02:30:18.884845Z","shell.execute_reply.started":"2025-12-01T02:30:18.858012Z","shell.execute_reply":"2025-12-01T02:30:18.883784Z"}},"outputs":[{"name":"stdout","text":"Q1: Which configuration has the minimum localization error?\n\nThe best configuration by RMSE is AlgorithmA with Gmapping ON for 2 minutes.\nRMSE = 0.0500 m, MAE = 0.0453 m, max error = 0.1030 m,\nCPU ≈ 35.0%, Memory ≈ 430.1 MB.\n\n================================================================================\n\nQ2: How does Gmapping affect localization for 10-minute runs?\n\nFor 10-minute runs:\n- Gmapping ON:  average RMSE = 0.2842 m\n- Gmapping OFF: average RMSE = 0.5383 m\n\nOn average, Gmapping ON shows 0.2542 m lower error compared to Gmapping OFF.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Demo: Conversational Analysis over Synthetic TB3 Experiments\n\nBelow, we query the OrchestratorAgent using natural language instructions:\n\n1. *“Which configuration has the minimum localization error?”*  \n2. *“How does Gmapping affect localization for 10-minute runs?”*\n\nThe Orchestrator delegates numeric work to the DataAnalysisAgent, \nwhich calculates localization metrics directly from the CSV logs. \nThe ExplanationAgent translates the results into concise insights, \nwhile interaction history is stored in the MemoryStore to support follow-up queries.\n\nThe current prototype uses deterministic Python tools to compute metrics such as RMSE, MAE, \nand CPU/memory averages. These computations remain transparent and reproducible — a requirement in robotics research.\n\nIn a production deployment, the orchestration and conversational layers would be powered by \nGemini Agents, enabling:\n- Multi-step reasoning over large experiment sets,\n- Richer natural language interaction,\n- Persistent memory across research sessions.\n\nThis hybrid design ensures that scientific evaluation remains grounded in deterministic computation, \nwhile leveraging LLM agents for interpretation, question decomposition, and experiment guidance.\n","metadata":{}}]}